{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47caa67",
   "metadata": {},
   "source": [
    "# Generating Dataset for Channel Estimation Training\n",
    "The first step in any deep learning project is preparing the dataset. In this notebook we create an OFDM communication pipeline and capture the received grid together with the transmitted grid containing DMRS information. We are assuming a Multi-layer MIMO configuration with 2 layers, 16 transmiter antenna, 4 receiver antenna. In this configuration each slot can carry 4 code-blocks. Each sample of dataset is a ``6 x 14 x 540`` tensor and ground-truth labels are ``4 x 14 x 540`` tesnors. \n",
    "The following picture shows how each dataset sample is created. The communication of each slot generates 4 dataset samples (one for each receiver antenna). In this experiment we are using $N_L = 2$ (Number of Layers), $L=14$ (Number of time-symbols), $K=540$ (Number of sub-carriers), and $N_r=4$ (Number of receiver antenna).\n",
    "\n",
    "Please note that since we are using DMRS for channel estimation, the \"channel\" includes the effect of precoding.\n",
    "\n",
    "![Data Generation Pipeline](ModelIO.png)\n",
    "\n",
    "So, let's get started by importing some modules from **NeoRadium**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2415601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time, os\n",
    "\n",
    "from neoradium import Carrier, PDSCH, CdlChannel, AntennaPanel, Grid, random, LdpcEncoder\n",
    "from ChEstUtils import getRandomPilotInfo, getModelIn, getLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f76984",
   "metadata": {},
   "source": [
    "The ``makeDataset`` function below runs the pipeline and creates samples with 0 (DMRS only), 1, 2, or 3 successfully decoded code-blocks. Please refer to the ``ChEstUtils.py`` file for the implementation details of the functions ``getRandomPilotInfo``, ``getModelIn``, and ``getLabels``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a21d14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataset(numSlots, snrDbs, seed, pdsch, fileName=None, freqDomain=True):\n",
    "    bwp = pdsch.bwp                       # The only bandwidth part in the carrier\n",
    "\n",
    "    # We don't need to use channel coding in the pipeline during dataset generation. However, we need\n",
    "    # to know the code-block sizes to be able to find the corresponding REs in the grid. The following \n",
    "    # code calculates the code-block sizes for each one of 4 code-blocks\n",
    "    ldpcEncoder = LdpcEncoder(baseGraphNo=1, modulation=pdsch.modems[0].modulation,\n",
    "                              txLayers=pdsch.numLayers, targetRate=490/1024)\n",
    "    txGrid = pdsch.getGrid()                                    # Create a resource grid populated with DMRS\n",
    "    numBits = pdsch.getBitSizes(txGrid)[0]                      # Number of bits available in the resource grid\n",
    "    txBlockSize = pdsch.getTxBlockSize(ldpcEncoder.targetRate)  # Transport Block Size based on TS 38.214\n",
    "    txBlock = random.bits(txBlockSize[0])                       # Create random binary data\n",
    "    rateMatchedCBs = ldpcEncoder.getRateMatchedCodeBlocks(txBlock, numBits, concatCBs=False)\n",
    "    cbSizes = [len(cb) for cb in rateMatchedCBs]                # Code-block sizes\n",
    "\n",
    "    # Creating a random CDL channel matrix generator \n",
    "    chanGen = CdlChannel.getChanGen(numSlots, carrier.curBwp,   # Number of channels and bandwidth part\n",
    "                                    profiles=\"ABCDE\",           # Randomly pick a CDL profile\n",
    "                                    delaySpread=300,            # 300 ns\n",
    "                                    ueSpeed=0.5,                # 0.5 mps â‰ˆ 6.7Hz doppler\n",
    "                                    carrierFreq=4e9,            # Carrier frequency\n",
    "                                    txAntenna=AntennaPanel([2,4], polarization=\"x\"),  # 16 TX antenna\n",
    "                                    rxAntenna=AntennaPanel([1,2], polarization=\"x\"),  # 4 RX antenna\n",
    "                                    seed=seed)\n",
    "    \n",
    "    samples, labels = [], []                        # Initialize samples and labels\n",
    "    t0 = time.time()                                # Start time for time estimation\n",
    "    random.setSeed(seed)\n",
    "    print(f\"Making dataset for {numSlots:,} slots\")\n",
    "    for s, channelMatrix in enumerate(chanGen):\n",
    "        txGrid = pdsch.getGrid()                    # Create a resource grid populated with DMRS\n",
    "        numBits = pdsch.getBitSizes(txGrid)[0]      # Number of bits available in the resource grid\n",
    "        txBits = random.bits(numBits)               # Create random binary data\n",
    "        pdsch.populateGrid(txGrid, txBits)          # Map/modulate the data to the resource grid\n",
    "\n",
    "        # Getting the Precoding Matrix, and precoding the resource grid\n",
    "        precoder = pdsch.getPrecodingMatrix(channelMatrix)      # Get the precoder matrix from PDSCH object\n",
    "        perfectChannel = channelMatrix @ precoder[None,...]     # ground truth channel with the effect of precoding\n",
    "        precodedGrid = txGrid.precode(precoder)                 # Perform the precoding\n",
    "        \n",
    "        snrDb = snrDbs[s%len(snrDbs)]               # Get next SNR value\n",
    "\n",
    "        if freqDomain:\n",
    "            rxGrid = precodedGrid.applyChannel(channelMatrix)   # Apply the channel in frequency domain\n",
    "            noisyRxGrid = rxGrid.addNoise(snrDb=snrDb)\n",
    "        else:\n",
    "            channel = chanGen.curChan                           # Get the channel model\n",
    "            txWaveform = precodedGrid.ofdmModulate()            # OFDM Modulation\n",
    "            maxDelay = channel.getMaxDelay()                    # Get the max. channel delay\n",
    "            txWaveform = txWaveform.pad(maxDelay)               # Pad with zeros\n",
    "            rxWaveform = channel.applyToSignal(txWaveform)      # Apply channel in time domain\n",
    "            noisyRxWaveform = rxWaveform.addNoise(snrDb=snrDb, nFFT=bwp.nFFT)  # Add noise\n",
    "            offset = channel.getTimingOffset()                  # Get timing info for synchronization\n",
    "            syncedWaveform = noisyRxWaveform.sync(offset)       # Synchronization\n",
    "            noisyRxGrid = syncedWaveform.ofdmDemodulate(bwp)    # OFDM demodulation\n",
    "        \n",
    "        # pilotIdx contains the indexes in the txGrid with known values. Known values could include DMRS\n",
    "        # and a number of successfuly decoded code-blocks (0..numCBs-1)\n",
    "        pilotIdx = getRandomPilotInfo(pdsch, txGrid, cbSizes)\n",
    "        newSamples = getModelIn(pilotIdx, txGrid, noisyRxGrid, 10000)   # rr x 2*(pp+1) x ll x kk\n",
    "        newLabels = getLabels( perfectChannel )                         # rr x 2*pp x ll x kk\n",
    "\n",
    "        samples += [ newSamples ]\n",
    "        labels += [ newLabels ]\n",
    "\n",
    "        dt = time.time()-t0                                     # Get the duration of time since the beginning\n",
    "        percentDone = (s+1)*100/numSlots                        # Calculate the percentage of task done\n",
    "\n",
    "        # Print messages about the progress\n",
    "        remainTime = int(np.round(100*dt/percentDone-dt))       # Estimated remaining time\n",
    "        print(f\"  {int(percentDone)}% done in {int(np.round(dt)):,} Sec., Remaining time: {remainTime:,} Sec.\",\n",
    "              end='            \\r')\n",
    "\n",
    "    # n: Number of samples in the dataset, pp: Number of ports, ll: Number of OFDM symbols, kk: Number of subcarriers\n",
    "    samples = np.concatenate(samples, axis=0)       # n x 2*(pp+1) x ll x kk\n",
    "    labels = np.concatenate(labels, axis=0)         # n x 2*pp x ll x kk\n",
    "\n",
    "    if fileName is not None:\n",
    "        np.save(fileName, np.concatenate([samples,labels],axis=1))   # Save the dataset to the specified file\n",
    "        print(f\"\\r  Done. ({dt:.2f} Sec.) Saved to \\\"{fileName}\\\".                       \")\n",
    "    else:\n",
    "        print(f\"\\r  Done. ({dt:.2f} Sec.)                                                \")\n",
    "\n",
    "    return samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d0dfbbf-1d49-472b-b7c0-c21f296f0970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making dataset for 17,500 slots\n",
      "  Done. (975.53 Sec.) Saved to \"/data/datasets/SelfRefine/Train.npy\".                       \n",
      "Making dataset for 2,500 slots\n",
      "  Done. (140.02 Sec.) Saved to \"/data/datasets/SelfRefine/Valid.npy\".                       \n",
      "Making dataset for 5,000 slots\n",
      "  Done. (279.61 Sec.) Saved to \"/data/datasets/SelfRefine/Test.npy\".                       \n"
     ]
    }
   ],
   "source": [
    "carrier = Carrier(numRbs=45, spacing=30)    # Create a carrier with 45 RBs and 30KHz subcarrier spacing\n",
    "bwp = carrier.curBwp                        # The only bandwidth part in the carrier\n",
    "\n",
    "# Create a 2-layer PDSCH object with type-2 DMRS on symbols 2 and 11\n",
    "pdsch = PDSCH(bwp, numLayers=2, nID=carrier.cellId, modulation=\"16QAM\")\n",
    "pdsch.setDMRS(configType=2, additionalPos=1)\n",
    "\n",
    "dataPath = \"/data/datasets/SelfRefine/\"     # Replace with the location of your data files\n",
    "os.makedirs(dataPath, exist_ok=True)        # Create data folder if it does not exist\n",
    "   \n",
    "snrDbs = np.arange(-15,-9,.5)               # Set the range of SNR values (in dB)\n",
    "\n",
    "# Create training, validation, and test dataset files (About 30GB of disk space needed):\n",
    "makeDataset(17500, snrDbs, seed=123, pdsch=pdsch, fileName=os.path.join(dataPath,\"Train.npy\"))\n",
    "makeDataset(2500,  snrDbs, seed=456, pdsch=pdsch, fileName=os.path.join(dataPath,\"Valid.npy\"))\n",
    "makeDataset(5000,  snrDbs, seed=789, pdsch=pdsch, fileName=os.path.join(dataPath,\"Test.npy\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233c660-c778-43a9-80d7-24434c7a5b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
