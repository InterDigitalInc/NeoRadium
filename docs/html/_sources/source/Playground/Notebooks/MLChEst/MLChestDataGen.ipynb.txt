{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47caa67",
   "metadata": {},
   "source": [
    "# Generating Dataset for Channel Estimation Training\n",
    "The first step in any deep learning project is preparing the dataset. In this notebook we create an OFDM communication pipeline and capture the received grid together with the DMRS information. Based on the known pilot signals (DMRS) and received values at those pilot locations, the Channel Estimation algorithms calculate the OFDM Channel Matrix for every pair of receive antenna and layer. Please note that since we are using DMRS pilots, the effect of precoding is included in the estimated channel.\n",
    "\n",
    "Our Deep learning model is trained to predict one ``L x K`` OFDM channel matrix where ``L`` is the number of OFDM symbols per slot and ``K`` is the number of subcarriers. However, the channel matrix is a 4-D tensor of shape ``L x K x Nr x Nl``, where ``Nr`` and ``Nl`` are the number of receiver antenna and the number of layers correspondingly. Therefore each channel matrix corresponds to ``Nc=Nr.Nl`` dataset samples. The following diagram shows how the data generation pipeline works.\n",
    "\n",
    "![Data Generation Pipeline](DataGenPipeline.png)\n",
    "\n",
    "So, let's get started by importing some modules from **NeoRadium**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2415601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import time\n",
    "\n",
    "from neoradium import Carrier, PDSCH, CdlChannel, AntennaPanel, Grid, random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2174d5",
   "metadata": {},
   "source": [
    "The ``getSamples`` function below receives the DMRS information, the received resource grid, and the ground-truth channel and creates pairs of dataset samples and labels. Each call to this function results in ``Nc=Nr.Nl`` dataset samples where ``Nr`` is the number of receiver antenna and ``Nl`` is the number of layers. This function first calculates the channel values at the pilot locations using least squares (LS) method. Each dataset sample is an ``L x K`` complex matrix which is initialized with zeros and updated by the channel values at pilot locations. The ground-truth channel is also broken down to ``Nc`` matrixes which are used as labels for the corresponding dataset samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a51dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSamples(dmrs, rxGrid, actualChannel):\n",
    "    rsGrid = rxGrid.bwp.createGrid( len(dmrs.pxxch.portSet) )   # Create an empty resource grid\n",
    "    dmrs.populateGrid(rsGrid)                                   # Populate the grid with DMRS values\n",
    "    rsIndexes = rsGrid.getReIndexes(\"DMRS\")                     # This contains the locations of DMRS values\n",
    "                                                                 \n",
    "    rr, ll, kk = rxGrid.shape           # Number of RX antenna, Number of symbols, Number of subcarriers\n",
    "    pp, ll2, kk2 = rsGrid.shape         # Number of Ports (From DMRS)\n",
    "    assert (ll==ll2) and (kk==kk2)\n",
    "\n",
    "    samples = []\n",
    "    labels = []\n",
    "\n",
    "    for p in range(pp):                             # For each DMRS port (i.e. each layer)\n",
    "        portLs = rsIndexes[1][(rsIndexes[0]==p)]    # Indexes of symbols containing pilots in this port\n",
    "        portKs = rsIndexes[2][(rsIndexes[0]==p)]    # Indexes of subcarriers containing pilots in this port\n",
    "\n",
    "        ls = np.unique(portLs)                      # Unique Indexes of symbols containing pilots in this port\n",
    "        ks = portKs[portLs==ls[0]]                  # Unique Indexes of subcarriers containing pilots in this port\n",
    "        numLs, numKs = len(ls), len(ks)             # Number of OFDM symbols and number of subcarriers\n",
    "\n",
    "        pilotValues = rsGrid[p,ls,:][:,ks]                              # Pilot values in this port\n",
    "        rxValues = rxGrid.grid[:,ls,:][:,:,ks]                          # Received values for pilot signals\n",
    "        hEst = np.transpose(rxValues/pilotValues[None,:,:], (1,2,0))    # Channel estimates at pilot locations\n",
    "\n",
    "        for r in range(rr):                                         # For each receiver antenna\n",
    "            inH = np.zeros(rxGrid.shape[1:], dtype=np.complex128)   # Create one 2D matrix with all zeros\n",
    "            for li,l in enumerate(ls):\n",
    "                inH[l,ks] = hEst[li,:,r]                            # Set the LS estimates at pilot location\n",
    "\n",
    "            samples += [ inH ]                  # The dataset sample for r'th antenna and p'th port (layer)\n",
    "            labels += [actualChannel[:,:,r,p]]  # The channel matrix (Label) for r'th antenna and p'th port (layer)\n",
    "    return samples, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00130b18",
   "metadata": {},
   "source": [
    "The ``makeDataset`` function below receives the number of time-domain frames (``numFrames``), the SNR values in dB (``snrDbs``), the seed values to initialize **NeoRadium**'s random generator (``seeds``), and a file name to save the dataset (``fileName``).\n",
    "\n",
    "It implements the communication pipeline shown in the above diagram. For each OFDM slot, it uses the ``getSamples`` function above to create samples and labels. These samples and labels are then aggregated and saved to the file specified by the ``fileName``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a21d14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataset(numFrames, snrDbs, seeds, fileName=None):\n",
    "    freqDomain = False                                  # Set to True to apply channel in frequency domain\n",
    "    carrier = Carrier(numRbs=51, spacing=30)            # Create a carrier with 51 RBs and 30KHz subcarrier spacing\n",
    "    bwp = carrier.curBwp                                # The only bandwidth part in the carrier\n",
    "\n",
    "    # Create a PDSCH object\n",
    "    pdsch = PDSCH(bwp, interleavingBundleSize=0, numLayers=2, nID=carrier.cellId, modulation=\"16QAM\")\n",
    "    pdsch.setDMRS(prgSize=0, configType=2, additionalPos=2) # Specify the DMRS configuration\n",
    "\n",
    "    numSlots = bwp.slotsPerFrame*numFrames                  # Total number of slots\n",
    "    samples, labels = [], []\n",
    "    totalIter = len(seeds) * numSlots * len(snrDbs)         # Total number of iterations\n",
    "    curIter = 1                                             # Counter used for printed messages\n",
    "    t0 = time.time()                                        # Start time for time estimation\n",
    "    print(\"Making dataset for SNR=%s dB, with %d frames and %d seeds\"%(str(snrDbs), numFrames, len(seeds)))\n",
    "    for s,seed in enumerate(seeds):                     # For each seed the channel is initialized differently\n",
    "        random.setSeed(seed)\n",
    "        carrier.slotNo = 0                              # Initialize the slot number\n",
    "    \n",
    "        # Creating a CdlChannel object:\n",
    "        channel = CdlChannel('C', delaySpread=300, carrierFreq=4e9, dopplerShift=5,\n",
    "                             txAntenna = AntennaPanel([2,2], polarization=\"x\"),  # 8 TX antenna\n",
    "                             rxAntenna = AntennaPanel([1,1], polarization=\"+\"),  # 2 RX antenna\n",
    "                             seed = seed,\n",
    "                             timing = \"nearest\")\n",
    "\n",
    "        for snrDb in snrDbs:                                # For each SNR value in snrDbs\n",
    "            for slotNo in range(numSlots):                  # For each slot in the specified number of frames\n",
    "                grid = pdsch.getGrid()                      # Create a resource grid populated with DMRS\n",
    "                numBits = pdsch.getBitSizes(grid)[0]        # Number of bits available in the resource grid\n",
    "                txBits = random.bits(numBits)               # Create random binary data\n",
    "\n",
    "                pdsch.populateGrid(grid, txBits)            # Map/modulate the data to the resource grid\n",
    "\n",
    "                channelMatrix = channel.getChannelMatrix(bwp)       # Get the (ground-truth) channel matrix\n",
    "                precoder = pdsch.getPrecodingMatrix(channelMatrix)  # Get the precoder matrix from the PDSCH object\n",
    "                precodedGrid = grid.precode(precoder)               # Perform the precoding\n",
    "\n",
    "                if freqDomain:\n",
    "                    rxGrid = precodedGrid.applyChannel(channelMatrix)   # Apply the channel in frequency domain\n",
    "                    rxGrid = rxGrid.addNoise(snrDb=snrDb)               # Add noise\n",
    "                else:\n",
    "                    txWaveform = precodedGrid.ofdmModulate()            # OFDM Modulation\n",
    "                    maxDelay = channel.getMaxDelay()                    # Get the max. channel delay\n",
    "                    txWaveform = txWaveform.pad(maxDelay)               # Pad with zeros\n",
    "                    rxWaveform = channel.applyToSignal(txWaveform)      # Apply channel in time domain\n",
    "                    noisyRxWaveform = rxWaveform.addNoise(snrDb=snrDb, nFFT=bwp.nFFT)  # Add noise\n",
    "                    offset = channel.getTimingOffset()                  # Get timing info for synchronization\n",
    "                    syncedWaveform = noisyRxWaveform.sync(offset)       # Synchronization\n",
    "                    rxGrid = syncedWaveform.ofdmDemodulate(bwp)         # OFDM demodulation\n",
    "\n",
    "                # Get the dataset samples and labels for current slot\n",
    "                newSamples, newLabels = getSamples(pdsch.dmrs, rxGrid, channelMatrix @ precoder[None,...])\n",
    "                samples += newSamples\n",
    "                labels += newLabels\n",
    "\n",
    "                carrier.goNext()                        # Prepare the carrier object for the next slot\n",
    "                channel.goNext()                        # Prepare the channel model for the next slot\n",
    "\n",
    "                dt = time.time()-t0                     # Get the duration of time since the beginning\n",
    "                percentDone = curIter*100/totalIter     # Calculate the percentage of task done\n",
    "\n",
    "                if curIter == totalIter: continue       # Last iteration\n",
    "                    \n",
    "                # Print messages about the progress\n",
    "                print(\"\\r  %%%d done in %d Sec. Estimated remaining time: %d Sec.  \"%\n",
    "                      (int(percentDone), np.round(dt), np.round(100*dt/percentDone-dt)), end='')\n",
    "                curIter += 1\n",
    "                \n",
    "    # Convert the samples and labels to numpy arrays with float values. Shape: N x L x K x 2\n",
    "    # N: Number of samples in the dataset, L: Number of OFDM symbols, K: Number of subcarriers, 2: Real/Imag\n",
    "    samples = np.stack([np.stack(samples).real, np.stack(samples).imag], axis=3)\n",
    "    labels = np.stack([np.stack(labels).real, np.stack(labels).imag], axis=3)\n",
    "\n",
    "    if fileName is not None:\n",
    "        np.save(fileName, np.stack([samples,labels]))   # Save the dataset to the specified file\n",
    "        print(\"\\r  Done. (%.2f Sec.) Saved to \\\"%s\\\".                        \"%(dt, fileName))\n",
    "    else:\n",
    "        print(\"\\r  Done. (%.2f Sec.)                                                   \"%(dt))\n",
    "\n",
    "    return samples, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be627f14",
   "metadata": {},
   "source": [
    "Now we can create the datasets for our deep learning project. The followin cell create 3 dataset files for training, validation, and test. We use 2 frames for time duration and create dataset using a mixture of SNR values 5, 10, 15, 20, and 25 dB.\n",
    "Different seeds are used for different datasets to make sure the data in validation and test datasets are not experienced by the model during the training. Depending on your machine, it can take 10 to 60 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebea1216",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making dataset for SNR=[5, 10, 15, 20, 25] dB, with 2 frames and 20 seeds\n",
      "  Done. (447.06 Sec.) Saved to \"ChestTrain.npy\".                        \n",
      "Making dataset for SNR=[5, 10, 15, 20, 25] dB, with 2 frames and 3 seeds\n",
      "  Done. (68.59 Sec.) Saved to \"ChestValid.npy\".                        \n",
      "Making dataset for SNR=[5, 10, 15, 20, 25] dB, with 2 frames and 3 seeds\n",
      "  Done. (67.99 Sec.) Saved to \"ChestTest.npy\".                        \n"
     ]
    }
   ],
   "source": [
    "random.setSeed(123)\n",
    "trainSample, trainlabels = makeDataset(numFrames=2, snrDbs=[5,10,15,20,25], \n",
    "                                       seeds=random.integers(1000, 2000, 20), fileName=\"ChestTrain.npy\")\n",
    "validSample, validlabels = makeDataset(numFrames=2, snrDbs=[5,10,15,20,25], \n",
    "                                       seeds=random.integers(2000, 3000, 3), fileName=\"ChestValid.npy\")\n",
    "testSample, testlabels = makeDataset(numFrames=2, snrDbs=[5,10,15,20,25], \n",
    "                                       seeds=random.integers(3000, 4000, 3), fileName=\"ChestTest.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f0732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
